{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa113690-75fd-467e-8e4f-781bb9dd012c",
   "metadata": {},
   "source": [
    "# The Basics of Supervised NLP Tasks - School Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e88696-b95b-47ed-823d-f0727c72ece4",
   "metadata": {},
   "source": [
    "## 0 - Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58c612a-b621-4c45-a35b-ca0f3bd1f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6823a5-5584-4138-9c0b-7587abab3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# import requests\n",
    "# url = \"https://github.com/shaypal5/tau_text_mining_24_5/raw/refs/heads/main/lecture_4/kindle_reviews_tau.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036b2c0d-ba84-44dc-bfab-9bb5229ebccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = requests.get(url).content\n",
    "# df = pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc91c9e1-9444-4ddd-820f-e2d2eeb3443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kindle_reviews_tau.csv')  # use this line instead if you've downloaded the dataset directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70064b4-4763-489c-b8f7-8a353335a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>total_votes_on_helpfulness</th>\n",
       "      <th>is_helpful_votes</th>\n",
       "      <th>is_helpful_ratio</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>yearly_income</th>\n",
       "      <th>is_married</th>\n",
       "      <th>favorite_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000FA64PA</td>\n",
       "      <td>5</td>\n",
       "      <td>I think I have this one in both book and audio...</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1ZT7WV0ZUA0OJ</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Audio and book</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43953</td>\n",
       "      <td>False</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000FA64PK</td>\n",
       "      <td>5</td>\n",
       "      <td>This one promises to be another good book. I h...</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1ZT7WV0ZUA0OJ</td>\n",
       "      <td>Mike</td>\n",
       "      <td>my collection</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43953</td>\n",
       "      <td>False</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>5</td>\n",
       "      <td>I was hoping to find this one in book form. Th...</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1ZT7WV0ZUA0OJ</td>\n",
       "      <td>Mike</td>\n",
       "      <td>my e- collection</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43953</td>\n",
       "      <td>False</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000FBFMVG</td>\n",
       "      <td>5</td>\n",
       "      <td>I love the stories with Chewie in them! this e...</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1ZT7WV0ZUA0OJ</td>\n",
       "      <td>Mike</td>\n",
       "      <td>my collection</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43953</td>\n",
       "      <td>False</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000FC26RI</td>\n",
       "      <td>4</td>\n",
       "      <td>As an aspiring yogini this is required reading...</td>\n",
       "      <td>02 13, 2013</td>\n",
       "      <td>A2Y1X56N8NPH8G</td>\n",
       "      <td>Heather \"Houndog\"</td>\n",
       "      <td>A good resource</td>\n",
       "      <td>1360713600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>23498</td>\n",
       "      <td>False</td>\n",
       "      <td>Non-Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  B000FA64PA        5  I think I have this one in both book and audio...   \n",
       "1  B000FA64PK        5  This one promises to be another good book. I h...   \n",
       "2  B000FA64QO        5  I was hoping to find this one in book form. Th...   \n",
       "3  B000FBFMVG        5  I love the stories with Chewie in them! this e...   \n",
       "4  B000FC26RI        4  As an aspiring yogini this is required reading...   \n",
       "\n",
       "    reviewTime      reviewerID       reviewerName           summary  \\\n",
       "0  01 27, 2014  A1ZT7WV0ZUA0OJ               Mike    Audio and book   \n",
       "1  01 27, 2014  A1ZT7WV0ZUA0OJ               Mike     my collection   \n",
       "2  01 27, 2014  A1ZT7WV0ZUA0OJ               Mike  my e- collection   \n",
       "3  01 27, 2014  A1ZT7WV0ZUA0OJ               Mike     my collection   \n",
       "4  02 13, 2013  A2Y1X56N8NPH8G  Heather \"Houndog\"   A good resource   \n",
       "\n",
       "   unixReviewTime  total_votes_on_helpfulness  is_helpful_votes  \\\n",
       "0      1390780800                           0                 0   \n",
       "1      1390780800                           1                 0   \n",
       "2      1390780800                           0                 0   \n",
       "3      1390780800                           0                 0   \n",
       "4      1360713600                           0                 0   \n",
       "\n",
       "   is_helpful_ratio  age gender     state  yearly_income  is_married  \\\n",
       "0               0.0   23   Male      Utah          43953       False   \n",
       "1               0.0   23   Male      Utah          43953       False   \n",
       "2               0.0   23   Male      Utah          43953       False   \n",
       "3               0.0   23   Male      Utah          43953       False   \n",
       "4               0.0   21   Male  Oklahoma          23498       False   \n",
       "\n",
       "  favorite_genre  \n",
       "0         Horror  \n",
       "1         Horror  \n",
       "2         Horror  \n",
       "3         Horror  \n",
       "4    Non-Fiction  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d5ea3e9-d079-4af0-a944-f37ff649ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97969"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d590a-5c93-40d5-be0d-5e26f905afe7",
   "metadata": {},
   "source": [
    "## 1 - Basic, text-less Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3672f1-719c-4303-ae44-846f2197d6ed",
   "metadata": {},
   "source": [
    "### 1.1 - Text-less Prediction w/ Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0779a3a-7565-4d33-9711-92afae33ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f60378f-1527-4b4f-965b-a5b9831dd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only non-textual features and the target column\n",
    "features = df[['overall', 'unixReviewTime', 'age', 'gender', 'state', 'yearly_income', \n",
    "              'is_married', 'favorite_genre']]\n",
    "target = df['is_helpful_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c7e148-b170-477b-b324-f9cc7947a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation, and test sets\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=0)\n",
    "train_features, val_features, train_target, val_target = train_test_split(\n",
    "    train_features, train_target, test_size=0.25, random_state=0)  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb2894a-1d62-4337-a7c9-41dccf80449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining numerical and categorical columns\n",
    "numeric_features = ['overall', 'unixReviewTime', 'age', 'yearly_income']\n",
    "categorical_features = ['gender', 'state', 'is_married', 'favorite_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d292c646-6f16-425c-a22d-974e5b927730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column transformer with StandardScaler for numerical features and OneHotEncoder for categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "316c5bd1-3c32-4a5e-961c-585c281951fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e580f03-260f-4f91-90e1-3fd46c6af6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV (although Linear Regression doesn't have hyperparameters, this is just to show the process)\n",
    "param_grid = {\n",
    "    # No hyperparameters for linear regression to tune\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aa838bd-755e-411e-92b7-87859f7b9ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['overall',\n",
       "                                                                          'unixReviewTime',\n",
       "                                                                          'age',\n",
       "                                                                          'yearly_income']),\n",
       "                                                                        ('cat',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['gender',\n",
       "                                                                          'state',\n",
       "                                                                          'is_married',\n",
       "                                                                          'favorite_genre'])])),\n",
       "                                       ('model', LinearRegression())]),\n",
       "             param_grid={}, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa719453-59e5-4b57-9f88-1526301f036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {}\n",
      "Best cross-validation score: 0.19540877344190127\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db2a13eb-84e3-4272-90ea-afe7dad2c3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.19655359360785832\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on validation data\n",
    "val_predictions = grid_search.predict(val_features)\n",
    "val_mse = mean_squared_error(val_target, val_predictions)\n",
    "print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb69307a-0c91-4467-81ba-4f9529da5a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.19544328271719746\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "test_predictions = grid_search.predict(test_features)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dfa898-465d-4bf9-9181-4bdc505bf629",
   "metadata": {},
   "source": [
    "### 1.2 - Now w/ SVR (Support Vector Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c598b3-00ce-4db1-940f-8f3bbf377e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64dfb2d0-f557-4b6a-b171-53810e9b6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the pipeline with SVR model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', SVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ef119b2-30c6-4705-b74d-5df24786336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define hyperparameter search space for SVR\n",
    "# param_grid = {\n",
    "#     'model__C': [1],\n",
    "#     'model__epsilon': [0.1, 0.5],\n",
    "#     'model__kernel': ['linear', 'rbf']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f619b11c-63ca-4d7a-bff8-335ae4a94500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform hyperparameter tuning with GridSearchCV\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c44ca04-ab8a-4be8-85a5-6c5c3a8cbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "# print(f\"Best cross-validation score: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5452d50-dc63-40b1-8e62-33eaf905b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluating the model on validation data\n",
    "# val_predictions = grid_search.predict(val_features)\n",
    "# val_mse = mean_squared_error(val_target, val_predictions)\n",
    "# print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e6e53d1-5f2f-4121-a5ba-e392269861c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final evaluation on the test set\n",
    "# test_predictions = grid_search.predict(test_features)\n",
    "# test_mse = mean_squared_error(test_target, test_predictions)\n",
    "# print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce23f0b-8b7b-4ddd-a804-cbbe70274dae",
   "metadata": {},
   "source": [
    "### 1.3 - Now w/ Decision Tree Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14e79dc3-3195-4b50-884f-e243880a04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31024e49-f9bd-4d3f-bd49-040754a4737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the pipeline with DecisionTreeRegressor model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', DecisionTreeRegressor(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20f5cff-d16d-4edd-a983-e17d49fd1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter search space for DecisionTreeRegressor\n",
    "param_grid = {\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 10, 20],\n",
    "    'model__min_samples_leaf': [1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3683bc8a-5629-45ba-b3a2-3677e3d06aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['overall',\n",
       "                                                                          'unixReviewTime',\n",
       "                                                                          'age',\n",
       "                                                                          'yearly_income']),\n",
       "                                                                        ('cat',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['gender',\n",
       "                                                                          'state',\n",
       "                                                                          'is_married',\n",
       "                                                                          'favorite_genre'])])),\n",
       "                                       ('model',\n",
       "                                        DecisionTreeRegressor(random_state=0))]),\n",
       "             param_grid={'model__max_depth': [None, 10, 20, 30],\n",
       "                         'model__min_samples_leaf': [1, 5, 10],\n",
       "                         'model__min_samples_split': [2, 10, 20]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform hyperparameter tuning with GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07b5874c-6b5e-447c-869a-26dfee1b0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__max_depth': 10, 'model__min_samples_leaf': 10, 'model__min_samples_split': 2}\n",
      "Best cross-validation score: 0.19775186145229967\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b88a63c1-78e4-4fa1-94aa-74ea4a5872f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.19821015564723315\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on validation data\n",
    "val_predictions = grid_search.predict(val_features)\n",
    "val_mse = mean_squared_error(val_target, val_predictions)\n",
    "print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25431171-fe6d-45d5-831e-2c1f20c3bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.1970154070226681\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "test_predictions = grid_search.predict(test_features)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b593ba-38e8-4924-87f2-a50f1d07ee21",
   "metadata": {},
   "source": [
    "## 2 - Review Text-only Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20f790ce-2865-49d5-ab62-bd3d0cc64409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c131419-18bc-4177-8467-b41c2afa829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'reviewText' and 'is_helpful_ratio' columns exist\n",
    "text_data = df['reviewText'].fillna(\"\")\n",
    "target = df['is_helpful_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bb415b2-991e-4e4f-b70b-e4d98bb9aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train_texts, test_texts, train_target, test_target = train_test_split(\n",
    "    text_data, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a53c74-5dfe-464e-864c-63248a4d45cd",
   "metadata": {},
   "source": [
    "### 2.1 - Text-only Prediction w/ BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "370a85a0-023d-4b1d-8a63-434de273c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer for Bag-of-Words model\n",
    "vectorizer = CountVectorizer(max_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd8d0c31-e38b-433e-a4c9-4b4108141146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text data\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "val_vectors = vectorizer.transform(val_texts)\n",
    "test_vectors = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc19f452-c89a-4e47-b961-7f15e4783363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dafa0b9-5bb3-4ebe-83d3-124e1982923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.20477957852470946\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test data\n",
    "test_predictions = model.predict(test_vectors)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af9a15-acec-48aa-9b4b-6a8710b64269",
   "metadata": {},
   "source": [
    "### 2.2 - Text-only Prediction w/ TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d64e463-345a-4c69-a14e-d3fde9fd78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77077621-60aa-4679-9b81-32e739b70431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace CountVectorizer with TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abedb712-4b70-441c-9702-faaa6ef0ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text data\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "val_vectors = vectorizer.transform(val_texts)\n",
    "test_vectors = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca81736e-5c1c-4f59-a644-ca1b58a8580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcffbc51-77bc-4c8b-9c9d-17a17b7e6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.20172754368771417\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test data\n",
    "test_predictions = model.predict(test_vectors)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f9528-1b81-43d7-adac-9e90a4690228",
   "metadata": {},
   "source": [
    "### 2.2 - Text-only Prediction w/ TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb4e548b-15b6-4e0a-9305-df361c129cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ace4c51a-fb97-4cea-a782-a8b24c50dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace vectorizer with SentenceTransformer and transform\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "transformer = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bb1eca4-1105-4dd0-b64d-b243b8ae1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train_texts, test_texts, train_target, test_target = train_test_split(\n",
    "    text_data, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e4686-75a8-487e-b48a-0a437a479da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array(transformer.encode(train_texts.tolist()))\n",
    "val_vectors = np.array(transformer.encode(val_texts.tolist()))\n",
    "test_vectors = np.array(transformer.encode(test_texts.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8beec0f-f013-4b30-abdc-1a018c59ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa5408-8ca0-4c52-ac3f-9906dfa9bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test data\n",
    "test_predictions = model.predict(test_vectors)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4741d181-d378-4e2e-a91d-3cf35362311e",
   "metadata": {},
   "source": [
    "## 3 - Text + Demographic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c1678df-f604-4e1d-a23d-991a351787f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0faef58f-2612-4d3f-9d7f-a7b60b8a76ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing reviewText values\n",
    "text_data = df['reviewText'].fillna(\"\")\n",
    "numeric_features = ['overall', 'unixReviewTime', 'age', 'yearly_income']\n",
    "categorical_features = ['gender', 'state', 'is_married', 'favorite_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fdc71c1-6ae8-4c71-8785-99cf8fbe3dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets\n",
    "train_texts, test_texts, train_target, test_target = train_test_split(\n",
    "    text_data, target, test_size=0.2, random_state=0)\n",
    "# train_texts, val_texts, train_target, val_target = train_test_split(\n",
    "#     train_texts, train_target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35855c16-19ed-40a3-b11a-1452e7abea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, _, _ = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=0)\n",
    "# train_features, val_features, _, _ = train_test_split(\n",
    "#     train_features, target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5ee584e-abdc-4bc4-b1c1-43f74e1eb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess non-text data using ColumnTransformer\n",
    "train_non_text_features = non_text_preprocessor.fit_transform(train_features)\n",
    "val_non_text_features = non_text_preprocessor.transform(val_features)\n",
    "test_non_text_features = non_text_preprocessor.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "25f769a6-32a0-4834-936e-17c940b95516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction using TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=40, random_state=0)\n",
    "train_reduced_text = svd.fit_transform(train_text_vectors)\n",
    "val_reduced_text = svd.transform(val_text_vectors)\n",
    "test_reduced_text = svd.transform(test_text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca7c91-f0ee-451c-9ad8-dc3be881f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the text features are reduced to a NumPy array, ensure the non-text features are preprocessed separately.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Continue with fitting the model\n",
    "model = LinearRegression()\n",
    "model.fit(train_combined_features, train_target)\n",
    "\n",
    "# Evaluate\n",
    "val_predictions = model.predict(val_combined_features)\n",
    "val_mse = mean_squared_error(val_target, val_predictions)\n",
    "print(f\"Validation MSE: {val_mse}\")\n",
    "\n",
    "test_predictions = model.predict(test_combined_features)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d7ea05e-42bb-4762-9eb9-fad15bf4e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine reduced text and other features\n",
    "train_combined_features = np.hstack([train_reduced_text, train_features])\n",
    "val_combined_features = np.hstack([val_reduced_text, val_features])\n",
    "test_combined_features = np.hstack([test_reduced_text, test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "940c15d1-495a-443f-ae16-465cfa6ff936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a preprocessor for non-text features\n",
    "non_text_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "836127c6-76e9-4903-83d4-63ffa0a6a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', non_text_preprocessor),\n",
    "                           ('model', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e556eee4-9e6d-4bb9-9725-5931adec9e22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sklearn/utils/__init__.py:409\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     all_columns \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit pipeline\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_combined_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sklearn/pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 390\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:672\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m--> 672\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    675\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:352\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    351\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 352\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sklearn/utils/__init__.py:411\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m     all_columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported for pandas DataFrames\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m     )\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    416\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [key]\n",
      "\u001b[0;31mValueError\u001b[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ],
   "source": [
    "# Fit pipeline\n",
    "pipeline.fit(train_combined_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdbfbc-a531-4832-9181-6463cbeb9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "val_predictions = pipeline.predict(val_combined_features)\n",
    "val_mse = mean_squared_error(val_target, val_predictions)\n",
    "print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601be842-38d8-4d03-9add-72ba367c084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_predictions = pipeline.predict(test_combined_features)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
