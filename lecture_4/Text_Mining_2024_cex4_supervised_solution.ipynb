{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa113690-75fd-467e-8e4f-781bb9dd012c",
   "metadata": {},
   "source": [
    "# The Basics of Supervised NLP Tasks - School Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e88696-b95b-47ed-823d-f0727c72ece4",
   "metadata": {},
   "source": [
    "## 0 - Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58c612a-b621-4c45-a35b-ca0f3bd1f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6823a5-5584-4138-9c0b-7587abab3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# import requests\n",
    "# url = \"https://github.com/shaypal5/tau_text_mining_24_5/raw/refs/heads/main/lecture_4/kindle_reviews_tau.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036b2c0d-ba84-44dc-bfab-9bb5229ebccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = requests.get(url).content\n",
    "# df = pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc91c9e1-9444-4ddd-820f-e2d2eeb3443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kindle_reviews_tau.csv')  # use this line instead if you've downloaded the dataset directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70064b4-4763-489c-b8f7-8a353335a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>total_votes_on_helpfulness</th>\n",
       "      <th>is_helpful_votes</th>\n",
       "      <th>is_helpful_ratio</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>yearly_income</th>\n",
       "      <th>is_married</th>\n",
       "      <th>favorite_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000FA64PA</td>\n",
       "      <td>5</td>\n",
       "      <td>I think I have this one in both book and audio...</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1ZT7WV0ZUA0OJ</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Audio and book</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43953</td>\n",
       "      <td>False</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000FA64PK</td>\n",
       "      <td>5</td>\n",
       "      <td>This one promises to be another good book. I h...</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1ZT7WV0ZUA0OJ</td>\n",
       "      <td>Mike</td>\n",
       "      <td>my collection</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43953</td>\n",
       "      <td>False</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>5</td>\n",
       "      <td>I was hoping to find this one in book form. Th...</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1ZT7WV0ZUA0OJ</td>\n",
       "      <td>Mike</td>\n",
       "      <td>my e- collection</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43953</td>\n",
       "      <td>False</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000FBFMVG</td>\n",
       "      <td>5</td>\n",
       "      <td>I love the stories with Chewie in them! this e...</td>\n",
       "      <td>01 27, 2014</td>\n",
       "      <td>A1ZT7WV0ZUA0OJ</td>\n",
       "      <td>Mike</td>\n",
       "      <td>my collection</td>\n",
       "      <td>1390780800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43953</td>\n",
       "      <td>False</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000FC26RI</td>\n",
       "      <td>4</td>\n",
       "      <td>As an aspiring yogini this is required reading...</td>\n",
       "      <td>02 13, 2013</td>\n",
       "      <td>A2Y1X56N8NPH8G</td>\n",
       "      <td>Heather \"Houndog\"</td>\n",
       "      <td>A good resource</td>\n",
       "      <td>1360713600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>23498</td>\n",
       "      <td>False</td>\n",
       "      <td>Non-Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  B000FA64PA        5  I think I have this one in both book and audio...   \n",
       "1  B000FA64PK        5  This one promises to be another good book. I h...   \n",
       "2  B000FA64QO        5  I was hoping to find this one in book form. Th...   \n",
       "3  B000FBFMVG        5  I love the stories with Chewie in them! this e...   \n",
       "4  B000FC26RI        4  As an aspiring yogini this is required reading...   \n",
       "\n",
       "    reviewTime      reviewerID       reviewerName           summary  \\\n",
       "0  01 27, 2014  A1ZT7WV0ZUA0OJ               Mike    Audio and book   \n",
       "1  01 27, 2014  A1ZT7WV0ZUA0OJ               Mike     my collection   \n",
       "2  01 27, 2014  A1ZT7WV0ZUA0OJ               Mike  my e- collection   \n",
       "3  01 27, 2014  A1ZT7WV0ZUA0OJ               Mike     my collection   \n",
       "4  02 13, 2013  A2Y1X56N8NPH8G  Heather \"Houndog\"   A good resource   \n",
       "\n",
       "   unixReviewTime  total_votes_on_helpfulness  is_helpful_votes  \\\n",
       "0      1390780800                           0                 0   \n",
       "1      1390780800                           1                 0   \n",
       "2      1390780800                           0                 0   \n",
       "3      1390780800                           0                 0   \n",
       "4      1360713600                           0                 0   \n",
       "\n",
       "   is_helpful_ratio  age gender     state  yearly_income  is_married  \\\n",
       "0               0.0   23   Male      Utah          43953       False   \n",
       "1               0.0   23   Male      Utah          43953       False   \n",
       "2               0.0   23   Male      Utah          43953       False   \n",
       "3               0.0   23   Male      Utah          43953       False   \n",
       "4               0.0   21   Male  Oklahoma          23498       False   \n",
       "\n",
       "  favorite_genre  \n",
       "0         Horror  \n",
       "1         Horror  \n",
       "2         Horror  \n",
       "3         Horror  \n",
       "4    Non-Fiction  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d5ea3e9-d079-4af0-a944-f37ff649ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97969"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d590a-5c93-40d5-be0d-5e26f905afe7",
   "metadata": {},
   "source": [
    "## 1 - Basic, text-less Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3672f1-719c-4303-ae44-846f2197d6ed",
   "metadata": {},
   "source": [
    "### 1.1 - Text-less Prediction w/ Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0779a3a-7565-4d33-9711-92afae33ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f60378f-1527-4b4f-965b-a5b9831dd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only non-textual features and the target column\n",
    "features = df[['overall', 'unixReviewTime', 'age', 'gender', 'state', 'yearly_income', \n",
    "              'is_married', 'favorite_genre']]\n",
    "target = df['is_helpful_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c7e148-b170-477b-b324-f9cc7947a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation, and test sets\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=0)\n",
    "train_features, val_features, train_target, val_target = train_test_split(\n",
    "    train_features, train_target, test_size=0.25, random_state=0)  # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bb2894a-1d62-4337-a7c9-41dccf80449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining numerical and categorical columns\n",
    "numeric_features = ['overall', 'unixReviewTime', 'age', 'yearly_income']\n",
    "categorical_features = ['gender', 'state', 'is_married', 'favorite_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d292c646-6f16-425c-a22d-974e5b927730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column transformer with StandardScaler for numerical features and OneHotEncoder for categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "316c5bd1-3c32-4a5e-961c-585c281951fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e580f03-260f-4f91-90e1-3fd46c6af6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV (although Linear Regression doesn't have hyperparameters, this is just to show the process)\n",
    "param_grid = {\n",
    "    # No hyperparameters for linear regression to tune\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aa838bd-755e-411e-92b7-87859f7b9ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['overall',\n",
       "                                                                          'unixReviewTime',\n",
       "                                                                          'age',\n",
       "                                                                          'yearly_income']),\n",
       "                                                                        ('cat',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['gender',\n",
       "                                                                          'state',\n",
       "                                                                          'is_married',\n",
       "                                                                          'favorite_genre'])])),\n",
       "                                       ('model', LinearRegression())]),\n",
       "             param_grid={}, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa719453-59e5-4b57-9f88-1526301f036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {}\n",
      "Best cross-validation score: 0.19540877344190127\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db2a13eb-84e3-4272-90ea-afe7dad2c3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.19655359360785832\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on validation data\n",
    "val_predictions = grid_search.predict(val_features)\n",
    "val_mse = mean_squared_error(val_target, val_predictions)\n",
    "print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb69307a-0c91-4467-81ba-4f9529da5a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.19544328271719746\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "test_predictions = grid_search.predict(test_features)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dfa898-465d-4bf9-9181-4bdc505bf629",
   "metadata": {},
   "source": [
    "### 1.2 - Now w/ SVR (Support Vector Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c598b3-00ce-4db1-940f-8f3bbf377e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64dfb2d0-f557-4b6a-b171-53810e9b6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the pipeline with SVR model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', SVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ef119b2-30c6-4705-b74d-5df24786336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define hyperparameter search space for SVR\n",
    "# param_grid = {\n",
    "#     'model__C': [1],\n",
    "#     'model__epsilon': [0.1, 0.5],\n",
    "#     'model__kernel': ['linear', 'rbf']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f619b11c-63ca-4d7a-bff8-335ae4a94500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform hyperparameter tuning with GridSearchCV\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c44ca04-ab8a-4be8-85a5-6c5c3a8cbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "# print(f\"Best cross-validation score: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5452d50-dc63-40b1-8e62-33eaf905b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluating the model on validation data\n",
    "# val_predictions = grid_search.predict(val_features)\n",
    "# val_mse = mean_squared_error(val_target, val_predictions)\n",
    "# print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e6e53d1-5f2f-4121-a5ba-e392269861c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final evaluation on the test set\n",
    "# test_predictions = grid_search.predict(test_features)\n",
    "# test_mse = mean_squared_error(test_target, test_predictions)\n",
    "# print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce23f0b-8b7b-4ddd-a804-cbbe70274dae",
   "metadata": {},
   "source": [
    "### 1.3 - Now w/ Decision Tree Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14e79dc3-3195-4b50-884f-e243880a04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31024e49-f9bd-4d3f-bd49-040754a4737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the pipeline with DecisionTreeRegressor model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', DecisionTreeRegressor(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20f5cff-d16d-4edd-a983-e17d49fd1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter search space for DecisionTreeRegressor\n",
    "param_grid = {\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 10, 20],\n",
    "    'model__min_samples_leaf': [1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3683bc8a-5629-45ba-b3a2-3677e3d06aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['overall',\n",
       "                                                                          'unixReviewTime',\n",
       "                                                                          'age',\n",
       "                                                                          'yearly_income']),\n",
       "                                                                        ('cat',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['gender',\n",
       "                                                                          'state',\n",
       "                                                                          'is_married',\n",
       "                                                                          'favorite_genre'])])),\n",
       "                                       ('model',\n",
       "                                        DecisionTreeRegressor(random_state=0))]),\n",
       "             param_grid={'model__max_depth': [None, 10, 20, 30],\n",
       "                         'model__min_samples_leaf': [1, 5, 10],\n",
       "                         'model__min_samples_split': [2, 10, 20]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform hyperparameter tuning with GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07b5874c-6b5e-447c-869a-26dfee1b0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__max_depth': 10, 'model__min_samples_leaf': 10, 'model__min_samples_split': 2}\n",
      "Best cross-validation score: 0.19775186145229967\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b88a63c1-78e4-4fa1-94aa-74ea4a5872f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.19821015564723315\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on validation data\n",
    "val_predictions = grid_search.predict(val_features)\n",
    "val_mse = mean_squared_error(val_target, val_predictions)\n",
    "print(f\"Validation MSE: {val_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25431171-fe6d-45d5-831e-2c1f20c3bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.1970154070226681\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the test set\n",
    "test_predictions = grid_search.predict(test_features)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b593ba-38e8-4924-87f2-a50f1d07ee21",
   "metadata": {},
   "source": [
    "## 2 - Review Text-only Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20f790ce-2865-49d5-ab62-bd3d0cc64409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c131419-18bc-4177-8467-b41c2afa829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'reviewText' and 'is_helpful_ratio' columns exist\n",
    "text_data = df['reviewText'].fillna(\"\")\n",
    "target = df['is_helpful_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bb415b2-991e-4e4f-b70b-e4d98bb9aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train_texts, test_texts, train_target, test_target = train_test_split(\n",
    "    text_data, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a53c74-5dfe-464e-864c-63248a4d45cd",
   "metadata": {},
   "source": [
    "### 2.1 - Text-only Prediction w/ BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "370a85a0-023d-4b1d-8a63-434de273c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer for Bag-of-Words model\n",
    "vectorizer = CountVectorizer(max_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd8d0c31-e38b-433e-a4c9-4b4108141146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text data\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "val_vectors = vectorizer.transform(val_texts)\n",
    "test_vectors = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc19f452-c89a-4e47-b961-7f15e4783363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dafa0b9-5bb3-4ebe-83d3-124e1982923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.20477957852470946\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test data\n",
    "test_predictions = model.predict(test_vectors)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af9a15-acec-48aa-9b4b-6a8710b64269",
   "metadata": {},
   "source": [
    "### 2.2 - Text-only Prediction w/ TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d64e463-345a-4c69-a14e-d3fde9fd78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77077621-60aa-4679-9b81-32e739b70431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace CountVectorizer with TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abedb712-4b70-441c-9702-faaa6ef0ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text data\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "val_vectors = vectorizer.transform(val_texts)\n",
    "test_vectors = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca81736e-5c1c-4f59-a644-ca1b58a8580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcffbc51-77bc-4c8b-9c9d-17a17b7e6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.20172754368771417\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test data\n",
    "test_predictions = model.predict(test_vectors)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f9528-1b81-43d7-adac-9e90a4690228",
   "metadata": {},
   "source": [
    "### 2.2 - Text-only Prediction w/ TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb4e548b-15b6-4e0a-9305-df361c129cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ace4c51a-fb97-4cea-a782-a8b24c50dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace vectorizer with SentenceTransformer and transform\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "transformer = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bb1eca4-1105-4dd0-b64d-b243b8ae1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train_texts, test_texts, train_target, test_target = train_test_split(\n",
    "    text_data, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "509e4686-75a8-487e-b48a-0a437a479da5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_texts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m val_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(transformer\u001b[38;5;241m.\u001b[39mencode(val_texts\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m      3\u001b[0m test_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(transformer\u001b[38;5;241m.\u001b[39mencode(test_texts\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:623\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 623\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    625\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:393\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    391\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 393\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/envs/py3/lib/python3.10/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_vectors = np.array(transformer.encode(train_texts.tolist()))\n",
    "val_vectors = np.array(transformer.encode(val_texts.tolist()))\n",
    "test_vectors = np.array(transformer.encode(test_texts.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8beec0f-f013-4b30-abdc-1a018c59ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa5408-8ca0-4c52-ac3f-9906dfa9bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test data\n",
    "test_predictions = model.predict(test_vectors)\n",
    "test_mse = mean_squared_error(test_target, test_predictions)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bab4d-2b56-4c7e-bc84-685b8bc6e802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
